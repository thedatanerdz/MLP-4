{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Telco Churn Analysis","metadata":{"_uuid":"3544313683eb7fc71db62dea38a54a3482efec26"}},{"cell_type":"markdown","source":"**Dataset Info:**\nSample Data Set containing Telco customer data and showing customers left last month","metadata":{"_uuid":"482057581152ac07ea4113aebf81ec6940aa7621"}},{"cell_type":"code","source":"#import the required libraries\nimport numpy as np \nimport pandas as pd \nimport seaborn as sns \nimport matplotlib.ticker as mtick  \nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n\n","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2023-05-24T00:53:06.851292Z","iopub.execute_input":"2023-05-24T00:53:06.851717Z","iopub.status.idle":"2023-05-24T00:53:06.858091Z","shell.execute_reply.started":"2023-05-24T00:53:06.851686Z","shell.execute_reply":"2023-05-24T00:53:06.857254Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"**Load the data file **","metadata":{"_uuid":"72e4750b2861fe4d89197b4c73ad861544701c4f"}},{"cell_type":"code","source":"telco_base_data = pd.read_csv(\"/kaggle/input/telecom-dataset/telco.csv\")","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.status.busy":"2023-05-24T00:54:20.471249Z","iopub.execute_input":"2023-05-24T00:54:20.471717Z","iopub.status.idle":"2023-05-24T00:54:20.666341Z","shell.execute_reply.started":"2023-05-24T00:54:20.471674Z","shell.execute_reply":"2023-05-24T00:54:20.664675Z"},"trusted":true},"execution_count":16,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m telco_base_data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/kaggle/input/telecom-dataset/telco.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/telecom-dataset/telco.csv'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/kaggle/input/telecom-dataset/telco.csv'","output_type":"error"}]},{"cell_type":"markdown","source":"Look at the top 5 records of data","metadata":{"_uuid":"2fd3487ed44d19c9794c5480e8c90078eebbbef6"}},{"cell_type":"code","source":"telco_base_data.head()","metadata":{"_uuid":"9dc64474af58b8114afb60f83cd1a002722ba74c","scrolled":true,"execution":{"iopub.status.busy":"2023-05-24T00:53:07.068084Z","iopub.status.idle":"2023-05-24T00:53:07.068569Z","shell.execute_reply.started":"2023-05-24T00:53:07.068309Z","shell.execute_reply":"2023-05-24T00:53:07.068329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Check the various attributes of data like shape (rows and cols), Columns, datatypes","metadata":{"_uuid":"09146f5b98d0ef400d5f646625ad383bce793af5"}},{"cell_type":"code","source":"telco_base_data.shape","metadata":{"_uuid":"b133d965a6a850e066086ca27f3957af3afec0a1","execution":{"iopub.status.busy":"2023-05-24T00:53:07.071024Z","iopub.status.idle":"2023-05-24T00:53:07.071447Z","shell.execute_reply.started":"2023-05-24T00:53:07.071245Z","shell.execute_reply":"2023-05-24T00:53:07.071263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"telco_base_data.columns.values","metadata":{"_uuid":"d814e5db6f76a4e90b8496f09d0ba340d1eae808","scrolled":true,"execution":{"iopub.status.busy":"2023-05-24T00:53:07.072765Z","iopub.status.idle":"2023-05-24T00:53:07.073179Z","shell.execute_reply.started":"2023-05-24T00:53:07.072981Z","shell.execute_reply":"2023-05-24T00:53:07.072999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The telco_base_data.columns.values expression is used to retrieve the column names of a DataFrame in pandas.","metadata":{}},{"cell_type":"code","source":"# Checking the data types of all the columns\ntelco_base_data.dtypes","metadata":{"_uuid":"641531c5f3131228c78e6a200e0410a161ccb2b0","execution":{"iopub.status.busy":"2023-05-24T00:53:07.074310Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The telco_base_data.dtypes expression is used to retrieve the data types of the columns in a pandas DataFrame called telco_base_data.","metadata":{}},{"cell_type":"code","source":"# Check the descriptive statistics of numeric variables\ntelco_base_data.describe()","metadata":{"_uuid":"04c3c0507e827f4c5b06c2d47441055a2cebc1bb","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The telco_base_data.describe() method is used to generate descriptive statistics of a pandas DataFrame called telco_base_data. It provides summary statistics for each numerical column in the DataFrame, such as count, mean, standard deviation, minimum value, maximum value, and quartile information.","metadata":{}},{"cell_type":"markdown","source":"SeniorCitizen is actually a categorical hence the 25%-50%-75% distribution is not proper\n\n75% customers have tenure less than 55 months\n\nAverage Monthly charges are USD 64.76 whereas 25% customers pay more than USD 89.85 per month","metadata":{"_uuid":"42023cf4f351bff8a06063bffe9fe23c6ec0ab4c"}},{"cell_type":"code","source":"telco_base_data['Churn'].value_counts().plot(kind='barh', figsize=(8, 6))\nplt.xlabel(\"Count\", labelpad=14)\nplt.ylabel(\"Target Variable\", labelpad=14)\nplt.title(\"Count of TARGET Variable per category\", y=1.02);\nplt.savefig('churn_count_plot.png')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The code snippet you provided is using the matplotlib library to create a horizontal bar plot of the counts of the 'Churn' variable in the telco_base_data DataFrame. It also adds labels to the x-axis, y-axis, and a title to the plot.This code will generate a horizontal bar plot that displays the counts of each category of the 'Churn' variable in the telco_base_data DataFrame. The x-axis represents the count, the y-axis represents the target variable categories, and the title provides a description of the plot.\n\nMake sure you have the necessary libraries (pandas and matplotlib) imported before running this code.","metadata":{}},{"cell_type":"code","source":"100*telco_base_data['Churn'].value_counts()/len(telco_base_data['Churn'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The code snippet you provided calculates the percentage distribution of each category in the 'Churn' variable of the telco_base_data DataFrame. It divides the count of each category by the total number of observations and multiplies by 100 to obtain the percentage.This code will calculate the percentage distribution of each category in the 'Churn' variable. The resulting output will be a pandas Series where the index represents the categories of the 'Churn' variable, and the values represent the corresponding percentage distribution.\n\nMake sure you have the necessary libraries (pandas) imported before running this code.","metadata":{}},{"cell_type":"code","source":"telco_base_data['Churn'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The code telco_base_data['Churn'].value_counts() calculates the count of each unique value in the 'Churn' column of the telco_base_data DataFrame. It returns a pandas Series where the index represents the unique values in the 'Churn' column, and the values represent their respective counts","metadata":{}},{"cell_type":"markdown","source":"* Data is highly imbalanced, ratio = 73:27<br>\n* So we analyse the data with other features while taking the target values separately to get some insights.","metadata":{}},{"cell_type":"code","source":"# Concise Summary of the dataframe, as we have too many columns, we are using the verbose = True mode\ntelco_base_data.info(verbose = True) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The telco_base_data.info(verbose=True) method provides a summary of the telco_base_data DataFrame, including the number of non-null values, data types, and memory usage. By setting verbose=True, you'll get a detailed output with information about each column.","metadata":{}},{"cell_type":"code","source":"missing = pd.DataFrame((telco_base_data.isnull().sum())*100/telco_base_data.shape[0]).reset_index()\nplt.figure(figsize=(16,5))\nax = sns.pointplot('index',0,data=missing)\nplt.xticks(rotation =90,fontsize =7)\nplt.title(\"Percentage of Missing values\")\nplt.ylabel(\"PERCENTAGE\")\nplt.show()\nplt.savefig('percentage_of_missing_values.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The code snippet you provided calculates the percentage of missing values for each column in the telco_base_data DataFrame and creates a point plot using the seaborn library. The resulting plot displays the percentage of missing values for each column.","metadata":{}},{"cell_type":"markdown","source":"### Missing Data - Initial Intuition\n\n* Here, we don't have any missing data.\n\nGeneral Thumb Rules:\n\n* For features with less missing values- can use regression to predict the missing values or fill with the mean of the values present, depending on the feature.\n* For features with very high number of missing values- it is better to drop those columns as they give very less insight on analysis.\n* As there's no thumb rule on what criteria do we delete the columns with high number of missing values, but generally you can delete the columns, if you have more than 30-40% of missing values. But again there's a catch here, for example, Is_Car & Car_Type, People having no cars, will obviously have Car_Type as NaN (null), but that doesn't make this column useless, so decisions has to be taken wisely.","metadata":{}},{"cell_type":"markdown","source":"## Data Cleaning\n","metadata":{"_uuid":"f8280f2a0edda71ef51a0ecbfc12d292a40f0989"}},{"cell_type":"markdown","source":"**1.** Create a copy of base data for manupulation & processing","metadata":{"_uuid":"3a1d2201066c4cfe149d6b71754d29ed41808539"}},{"cell_type":"code","source":"telco_data = telco_base_data.copy()","metadata":{"_uuid":"121b8594ada0e9d8c2a033c8e9fafef6ea5ea755","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**2.** Total Charges should be numeric amount. Let's convert it to numerical data type","metadata":{"_uuid":"d29d02dd08beaaab943c0d8b5e1d896db72396a8"}},{"cell_type":"code","source":"telco_data.TotalCharges = pd.to_numeric(telco_data.TotalCharges, errors='coerce')\ntelco_data.isnull().sum()","metadata":{"_uuid":"1d2c01029124a6fe73b3ec3fc4efdb66647d64e1","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**3.** As we can see there are 11 missing values in TotalCharges column. Let's check these records ","metadata":{"_uuid":"87478c110cb2c8fa7e98fd89719d9ae401cc791b"}},{"cell_type":"code","source":"telco_data.loc[telco_data ['TotalCharges'].isnull() == True]","metadata":{"_uuid":"4c518b444a2697db9364fcd5038e47e485401662","scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**4. Missing Value Treatement**","metadata":{"_uuid":"7657362c1ba2d5d1582d13926e46ca0d30574e20"}},{"cell_type":"markdown","source":"Since the % of these records compared to total dataset is very low ie 0.15%, it is safe to ignore them from further processing.","metadata":{"_uuid":"4c997dec9dbb501333f6a1562e9092e1008df58f"}},{"cell_type":"code","source":"#Removing missing values \ntelco_data.dropna(how = 'any', inplace = True)\n\n#telco_data.fillna(0)","metadata":{"_uuid":"cfd79280abe1d2238776bea1fdb7575c90a160bb","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The code telco_data.dropna(how='any', inplace=True) is used to drop rows from the telco_data DataFrame that contain any missing values (NaN values). The dropna() function is a pandas DataFrame method that removes rows or columns with missing values based on specified conditions.","metadata":{}},{"cell_type":"markdown","source":"**5.** Divide customers into bins based on tenure e.g. for tenure < 12 months: assign a tenure group if 1-12, for tenure between 1 to 2 Yrs, tenure group of 13-24; so on...","metadata":{"_uuid":"f287bc221478ee7f8945942f111e9f457f446218"}},{"cell_type":"code","source":"# Get the max tenure\nprint(telco_data['tenure'].max()) #72","metadata":{"_uuid":"35b6c18a5b84dd1e5fa014b49fcfce8ee43aaabe","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Based on the code snippet you provided (print(telco_data['tenure'].max())), it prints the maximum value of the 'tenure' column in the telco_data DataFrame, which is 72.","metadata":{}},{"cell_type":"code","source":"# Group the tenure in bins of 12 months\nlabels = [\"{0} - {1}\".format(i, i + 11) for i in range(1, 72, 12)]\n\ntelco_data['tenure_group'] = pd.cut(telco_data.tenure, range(1, 80, 12), right=False, labels=labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The code snippet you provided groups the 'tenure' column in the telco_data DataFrame into bins of 12 months and creates a new column called 'tenure_group' to store the respective bin labels.In this line, a list of labels is created for the tenure groups. Each label represents a range of 12 months, starting from 1 and incrementing by 12. For example, the first label will be \"1 - 12\", the second label will be \"13 - 24\", and so on, up to the maximum tenure of 72 months. n this line, the pd.cut() function is used to create the 'tenure_group' column based on the 'tenure' column values. The pd.cut() function takes the 'tenure' column as the first argument. The second argument, range(1, 80, 12), specifies the bin edges, starting from 1 and incrementing by 12 up to a maximum of 80. The right=False parameter indicates that the intervals should be left-closed (inclusive on the left side) and right-open. The labels=labels parameter assigns the previously created labels to the corresponding bins.\n\nAfter running this code, the telco_data DataFrame will have a new column called 'tenure_group' that categorizes the tenure values into bins of 12 months, with the corresponding labels assigned to each bin.","metadata":{}},{"cell_type":"code","source":"telco_data['tenure_group'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The code telco_data['tenure_group'].value_counts() calculates the count of each unique value in the 'tenure_group' column of the telco_data DataFrame. It returns a pandas Series where the index represents the unique values in the 'tenure_group' column, and the values represent their respective counts. This code will display the count of each unique value in the 'tenure_group' column of the telco_data DataFrame. The resulting output will be a pandas Series where the unique values in the 'tenure_group' column are shown as the index, and their respective counts are displayed as the values.\n\nYou can use this information to gain insights into the distribution of the 'tenure_group' variable in your dataset.","metadata":{}},{"cell_type":"markdown","source":"**6.** Remove columns not required for processing","metadata":{"_uuid":"c36ca32d5de932c55480842c31ef9b2ed657526c"}},{"cell_type":"code","source":"#drop column customerID and tenure\ntelco_data.drop(columns= ['customerID','tenure'], axis=1, inplace=True)\ntelco_data.head()","metadata":{"_uuid":"d95aa107c0ef519ea7e87a65a5fd41592dfa4091","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The code snippet you provided drops the 'customerID' and 'tenure' columns from the telco_data DataFrame using the drop() method. In this code, the drop() method is called on the telco_data DataFrame to remove the specified columns. The columns=['customerID', 'tenure'] parameter specifies the list of columns to drop. The axis=1 parameter indicates that the operation should be applied along the columns (i.e., drop columns). Finally, inplace=True ensures that the changes are applied to the telco_data DataFrame itself, modifying it directly.\n\nAfter running this code, the 'customerID' and 'tenure' columns will be removed from the telco_data DataFrame, and the resulting DataFrame will be displayed using the head() method to show the updated DataFrame with the specified columns dropped.","metadata":{}},{"cell_type":"markdown","source":"## Data Exploration\n**1. ** Plot distibution of individual predictors by churn","metadata":{"_uuid":"0339847e7ebf56e073d045b5b6c9296e7010d37b"}},{"cell_type":"markdown","source":"### Univariate Analysis","metadata":{}},{"cell_type":"code","source":"for i, predictor in enumerate(telco_data.drop(columns=['Churn', 'TotalCharges', 'MonthlyCharges'])):\n    plt.figure(i)\n    sns.countplot(data=telco_data, x=predictor, hue='Churn')\n    plt.savefig(f'countplot_{predictor}.png')\n   ","metadata":{"_uuid":"284f24631775ab8af6b43ce2e0269ddeb5c424c6","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The code snippet you provided creates countplots for each predictor column in the telco_data DataFrame, excluding the 'Churn', 'TotalCharges', and 'MonthlyCharges' columns. Each countplot shows the count of churned and non-churned customers for each unique value in the respective predictor column.The code snippet you provided creates countplots for each predictor column in the telco_data DataFrame, excluding the 'Churn', 'TotalCharges', and 'MonthlyCharges' columns. Each countplot shows the count of churned and non-churned customers for each unique value in the respective predictor column.In this code, the drop() method is used to exclude the 'Churn', 'TotalCharges', and 'MonthlyCharges' columns from the telco_data DataFrame, leaving only the predictor columns. The enumerate() function is used to iterate over the predictor columns, providing both the index (i) and the column name (predictor) in each iteration.\n\nWithin the loop, a new figure is created for each predictor using plt.figure(i). Then, the sns.countplot() function is called to create a countplot, where the predictor column is plotted on the x-axis (x=predictor), and the 'Churn' column is used to determine the hue (hue='Churn'), which separates the bars by churned and non-churned customers.\n\nFinally, plt.show() is used to display all the countplots.\n\nMake sure you have the necessary libraries (matplotlib and seaborn) imported before running this code.","metadata":{}},{"cell_type":"markdown","source":"**2.** Convert the target variable 'Churn'  in a binary numeric variable i.e. Yes=1 ; No = 0","metadata":{"_uuid":"ef3b7da7e8098c932689dea77fd8cbde162b52cb"}},{"cell_type":"code","source":"telco_data['Churn'] = np.where(telco_data.Churn == 'Yes',1,0)","metadata":{"_uuid":"a7ef7e130a32d73e886f0b4fa17d3f924fb5830a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The code snippet you provided converts the values in the 'Churn' column of the telco_data DataFrame from categorical strings ('Yes' and 'No') to numerical values (1 and 0) using the np.where() function from the NumPy library.","metadata":{}},{"cell_type":"code","source":"telco_data.head()","metadata":{"_uuid":"44d677eed9647fde82fa5eb2479918c9c9713362","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**3.** Convert all the categorical variables into dummy variables","metadata":{"_uuid":"a5573e75c6d2e700b1ca0f85f7b9b275094126da"}},{"cell_type":"code","source":"telco_data_dummies = pd.get_dummies(telco_data)\ntelco_data_dummies.head()","metadata":{"_uuid":"b0aee7309706a4c00a0c07fc831329495da630ce","scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The code snippet you provided creates dummy variables for categorical columns in the telco_data DataFrame using the pd.get_dummies() function from the pandas library. The resulting DataFrame, telco_data_dummies, will contain the original columns along with additional columns representing the dummy variables.","metadata":{}},{"cell_type":"markdown","source":"**9. ** Relationship between Monthly Charges and Total Charges","metadata":{"_uuid":"bde233534639a29066109e9061737460134e1c08"}},{"cell_type":"code","source":"sns.lmplot(data=telco_data_dummies, x='MonthlyCharges', y='TotalCharges', fit_reg=False)\nplt.savefig('Monthlychargesvstotalcharges.png')","metadata":{"_uuid":"1780f7d5cd6125ca347e6023b1d1e871fe36fde0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Total Charges increase as Monthly Charges increase - as expected.","metadata":{"_uuid":"9f5f9a41d7fc4eef9b8f9b04afbc3aceb3b41853"}},{"cell_type":"markdown","source":"The code snippet  provided creates a scatter plot using the lmplot() function from the seaborn library. The scatter plot visualizes the relationship between the 'MonthlyCharges' and 'TotalCharges' columns from the telco_data_dummies DataFrame.","metadata":{}},{"cell_type":"markdown","source":"**10. ** Churn by Monthly Charges and Total Charges","metadata":{"_uuid":"0b1896f1313b88e3e8b65c97aec56d2b96e87e21"}},{"cell_type":"code","source":"Mth = sns.kdeplot(telco_data_dummies.MonthlyCharges[(telco_data_dummies[\"Churn\"] == 0) ],\n                color=\"Red\", shade = True)\nMth = sns.kdeplot(telco_data_dummies.MonthlyCharges[(telco_data_dummies[\"Churn\"] == 1) ],\n                ax =Mth, color=\"Blue\", shade= True)\nMth.legend([\"No Churn\",\"Churn\"],loc='upper right')\nMth.set_ylabel('Density')\nMth.set_xlabel('Monthly Charges')\nMth.set_title('Monthly charges by churn')\nplt.savefig('KDE_montlychargesvschurn.png')","metadata":{"_uuid":"3579147afd1d8bad3dd8ffcbdf4cbba5f5f5876d","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Insight:** Churn is high when Monthly Charges ar high","metadata":{"_uuid":"758d5e017471d335a3947ea72b47980f93edda93"}},{"cell_type":"markdown","source":"The code snippet you provided creates a kernel density estimation (KDE) plot to visualize the distribution of monthly charges in relation to churn status in the telco_data_dummies DataFrame.In this code, two KDE plots are created using the kdeplot() function from seaborn:\n\n* The first kdeplot() call plots the kernel density estimation of the monthly charges for rows where 'Churn' equals 0 (non-churned customers). These charges are represented by telco_data_dummies.MonthlyCharges[(telco_data_dummies[\"Churn\"] == 0)]. The KDE plot is colored red and shaded.\n* The second kdeplot() call plots the kernel density estimation of the monthly charges for rows where 'Churn' equals 1 (churned customers). These charges are represented by telco_data_dummies.MonthlyCharges[(telco_data_dummies[\"Churn\"] == 1)]. The KDE plot is colored blue and shaded.\n* The ax=Mth parameter in the second kdeplot() call ensures that the second KDE plot is drawn on the same axes as the first plot, allowing for comparison.\n* The legend is set using Mth.legend([\"No Churn\", \"Churn\"], loc='upper right'), providing labels for the two KDE plots.\n* The y-axis label is set to 'Density' using Mth.set_ylabel('Density').\n* The x-axis label is set to 'Monthly Charges' using Mth.set_xlabel('Monthly Charges').\n* The title of the plot is set to 'Monthly charges by churn' using Mth.set_title('Monthly charges by churn').\n* Finally, plt.show() is used to display the KDE plot.\n\nMake sure you have the necessary libraries (seaborn, matplotlib.pyplot) imported before running this code.","metadata":{}},{"cell_type":"code","source":"Tot = sns.kdeplot(telco_data_dummies.TotalCharges[(telco_data_dummies[\"Churn\"] == 0) ],\n                color=\"Red\", shade = True)\nTot = sns.kdeplot(telco_data_dummies.TotalCharges[(telco_data_dummies[\"Churn\"] == 1) ],\n                ax =Tot, color=\"Blue\", shade= True)\nTot.legend([\"No Churn\",\"Churn\"],loc='upper right')\nTot.set_ylabel('Density')\nTot.set_xlabel('Total Charges')\nTot.set_title('Total charges by churn')\nplt.savefig('KDE_totalchargesvschurn.png')","metadata":{"_uuid":"0ff1683e472c29da849a00083cd2f45acdbb14b9","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Surprising insight ** as higher Churn at lower Total Charges\n\nHowever if we combine the insights of 3 parameters i.e. Tenure, Monthly Charges & Total Charges then the picture is bit clear :- Higher Monthly Charge at lower tenure results into lower Total Charge. Hence, all these 3 factors viz **Higher Monthly Charge**,  **Lower tenure** and **Lower Total Charge** are linkd to **High Churn**.","metadata":{"_uuid":"52abae69d9243dce608dfa63a0ebe12de83e7eff"}},{"cell_type":"markdown","source":"**11. Build a corelation of all predictors with 'Churn' **","metadata":{"_uuid":"ddd26520d541b1a3d17848e73d4cd6b3fbdc32d5"}},{"cell_type":"code","source":"plt.figure(figsize=(20,8))\ntelco_data_dummies.corr()['Churn'].sort_values(ascending = False).plot(kind='bar')\nplt.savefig('bargraph_corr.png')","metadata":{"_uuid":"57fad0b9bcd9188193c84ae48ea589123532eac8","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The code snippet you provided creates a bar plot to visualize the correlation values between the 'Churn' column and all other columns in the telco_data_dummies DataFrame. The correlation values are sorted in descending order, and the resulting plot displays the correlations in a bar chart. In this code, the plt.figure(figsize=(20, 8)) statement sets the figure size to (20, 8) inches.\n\nThe correlation values between the 'Churn' column and all other columns in the telco_data_dummies DataFrame are calculated using .corr()['Churn']. The resulting Series is then sorted in descending order using .sort_values(ascending=False).\n\nThe .plot(kind='bar') method is called to create a bar plot of the sorted correlation values. The resulting plot shows the correlation values on the y-axis and the column names on the x-axis, with bars representing the magnitude of the correlations.\n\nFinally, plt.show() is used to display the bar plot.\n\nMake sure you have the necessary library (matplotlib.pyplot) imported before running this code.","metadata":{}},{"cell_type":"markdown","source":"**Derived Insight: **\n\n**HIGH** Churn seen in case of  **Month to month contracts**, **No online security**, **No Tech support**, **First year of subscription** and **Fibre Optics Internet**\n\n**LOW** Churn is seens in case of **Long term contracts**, **Subscriptions without internet service** and **The customers engaged for 5+ years**\n\nFactors like **Gender**, **Availability of PhoneService** and **# of multiple lines** have alomost **NO** impact on Churn\n\nThis is also evident from the **Heatmap** below","metadata":{"_uuid":"e4f114358ce3d568a34c1ac419623274a345812e"}},{"cell_type":"code","source":"plt.figure(figsize=(12,12))\nsns.heatmap(telco_data_dummies.corr(), cmap=\"Paired\")\nplt.savefig('heatmat_corr.png')","metadata":{"_uuid":"9cafbb06245f6162da782bf0aa99faa3f6f9029d","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The code snippet you provided creates a heatmap using the heatmap() function from the seaborn library to visualize the correlation matrix of the telco_data_dummies DataFrame. The correlation values are represented as colors in the heatmap, with a color palette defined by the \"Paired\" colormap.","metadata":{"_uuid":"53befd3d7cceb497a7426deb30a7884e20a47ad7"}},{"cell_type":"markdown","source":"### Bivariate Analysis","metadata":{}},{"cell_type":"code","source":"new_df1_target0=telco_data.loc[telco_data[\"Churn\"]==0]\nnew_df1_target1=telco_data.loc[telco_data[\"Churn\"]==1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The code snippet you provided creates two new DataFrames, new_df1_target0 and new_df1_target1, by filtering the telco_data DataFrame based on the value of the 'Churn' column. In this code, the .loc[] indexing method is used to filter the telco_data DataFrame based on the condition telco_data[\"Churn\"] == 0 and telco_data[\"Churn\"] == 1, respectively. This creates two new DataFrames: new_df1_target0, which contains rows where the 'Churn' column is equal to 0 (representing non-churned customers), and new_df1_target1, which contains rows where the 'Churn' column is equal to 1 (representing churned customers).\n\nThese new DataFrames allow you to separate the data based on the churn status, which can be useful for further analysis or modeling specific to each group.\n\nPlease note that the assumption is made that the column name 'Churn' exists in the telco_data DataFrame.","metadata":{}},{"cell_type":"code","source":"def uniplot(df,col,title,hue =None):\n    \n    sns.set_style('whitegrid')\n    sns.set_context('talk')\n    plt.rcParams[\"axes.labelsize\"] = 20\n    plt.rcParams['axes.titlesize'] = 22\n    plt.rcParams['axes.titlepad'] = 30\n    \n    \n    temp = pd.Series(data = hue)\n    fig, ax = plt.subplots()\n    width = len(df[col].unique()) + 7 + 4*len(temp.unique())\n    fig.set_size_inches(width , 8)\n    plt.xticks(rotation=45)\n    plt.yscale('log')\n    plt.title(title)\n    ax = sns.countplot(data = df, x= col, order=df[col].value_counts().index,hue = hue,palette='bright') \n        \n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The code snippet you provided defines a function called uniplot() that can be used to create a count plot with additional customization options using seaborn and matplotlib.The uniplot() function takes the following parameters:\n\ndf: The pandas DataFrame containing the data to be plotted.\ncol: The column name in the DataFrame for which the count plot will be created.\ntitle: The title of the plot.\nhue (optional): The column name in the DataFrame used for color differentiation in the count plot.\nInside the function, the seaborn style and context are set to 'whitegrid' and 'talk', respectively, to provide a specific visual style for the plot. The font size and padding for the axes labels and title are also adjusted.\n\nA temporary series, temp, is created to hold the hue data.\n\nA figure and axes are created using plt.subplots(), and the size of the figure is adjusted based on the number of unique values in the col column and the number of unique values in the hue column.\n\nThe x-axis labels are rotated by 45 degrees for better readability, and the y-axis scale is set to logarithmic using plt.yscale('log').\n\nThe title of the plot is set using plt.title(title).\n\nThe count plot is created using sns.countplot(), where the data is specified as df, the x-axis column is specified as col, the order of the x-axis values is set based on the value counts of the column, and the hue column is specified as hue. The 'bright' palette is used for coloring the bars.\n\nFinally, the plot is displayed using plt.show().\n\nYou can call this function with your own DataFrame and desired parameters to create a customized count plot.","metadata":{}},{"cell_type":"code","source":"uniplot(new_df1_target1,col='Partner',title='Distribution of Gender for Churned Customers',hue='gender')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The uniplot() function you provided can be used to create a count plot that shows the distribution of the \"Partner\" column for churned customers, differentiated by gender. The title of the plot will be \"Distribution of Gender for Churned Customers\".","metadata":{}},{"cell_type":"code","source":"uniplot(new_df1_target0,col='Partner',title='Distribution of Gender for Non Churned Customers',hue='gender')\nplt.savefig('bar_partner.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To create a count plot that shows the distribution of the \"Partner\" column for non-churned customers, differentiated by gender, you can use the uniplot() function with the appropriate parameters. ","metadata":{}},{"cell_type":"code","source":"uniplot(new_df1_target1,col='PaymentMethod',title='Distribution of PaymentMethod for Churned Customers',hue='gender')\nplt.savefig('bar_payment_method.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\nTo create a count plot that shows the distribution of the \"PaymentMethod\" column for churned customers, differentiated by gender, you can use the uniplot() function with the appropriate parameters.","metadata":{}},{"cell_type":"code","source":"uniplot(new_df1_target1,col='Contract',title='Distribution of Contract for Churned Customers',hue='gender')\nplt.savefig('bar_contract.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To create a count plot that shows the distribution of the \"Contract\" column for churned customers, differentiated by gender, you can use the uniplot() function with the appropriate parameters. ","metadata":{}},{"cell_type":"code","source":"uniplot(new_df1_target1,col='TechSupport',title='Distribution of TechSupport for Churned Customers',hue='gender')\nplt.savefig('bar_techsupport.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To create a count plot that shows the distribution of the \"TechSupport\" column for churned customers, differentiated by gender, you can use the uniplot() function with the appropriate parameters. ","metadata":{}},{"cell_type":"code","source":"uniplot(new_df1_target1,col='SeniorCitizen',title='Distribution of SeniorCitizen for Churned Customers',hue='gender')\nplt.savefig('bar_sensior.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To create a count plot that shows the distribution of the \"SeniorCitizen\" column for churned customers, differentiated by gender, you can use the uniplot() function with the appropriate parameters. ","metadata":{}},{"cell_type":"markdown","source":"# CONCLUSION","metadata":{}},{"cell_type":"markdown","source":"These are some of the quick insights from this exercise:\n\n1. Electronic check medium are the highest churners\n2. Contract Type - Monthly customers are more likely to churn because of no contract terms, as they are free to go customers.\n3. No Online security, No Tech Support category are high churners\n4. Non senior Citizens are high churners\n\n","metadata":{}},{"cell_type":"code","source":"telco_data_dummies.to_csv('tel_churn.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To save the telco_data_dummies DataFrame as a CSV file named 'tel_churn.csv', you can use the to_csv() function.","metadata":{}}]}